{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils import fuse_conv_bn_eval\n",
    "\n",
    "from model import SDN, FusedSDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Architecture hyper-parametersm, checkpoint and helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 8\n",
    "kernel_size = 8\n",
    "n_layers = 1\n",
    "save_file = \"sdn.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"exp1/best_checkpoint.pth\" # specific the checkpoint you want to convert\n",
    "checkpoint = torch.load(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_parameter(target, source):\n",
    "    target.data.copy_(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Build models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Build SDN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SDN(d_model, kernel_size, n_layers)\n",
    "model.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Build fused SDN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model = FusedSDN(d_model, kernel_size, n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `dtype` of models to `double` in order to avoid precision errors and switch them to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FusedSDN(\n",
       "  (encoder): Conv1d(1, 8, kernel_size=(1,), stride=(1,), padding=(1,), bias=False)\n",
       "  (spatial_layers): ModuleList(\n",
       "    (0): Conv1d(1, 8, kernel_size=(8,), stride=(1,), padding=(8,))\n",
       "  )\n",
       "  (feature_layers): ModuleList(\n",
       "    (0): Conv1d(8, 8, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (decoder): Conv1d(8, 1, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.double().eval()\n",
    "fused_model.double().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuse the encoder into the first spatial layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_parameter(\n",
    "    fused_model.spatial_layers[0].weight,\n",
    "    model.encoder.weight * model.spatial_layers[0][0].weight,\n",
    ")\n",
    "copy_parameter(fused_model.spatial_layers[0].bias, model.spatial_layers[0][0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuse all bn layers into its previous `conv1d` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model.spatial_layers[0] = fuse_conv_bn_eval(\n",
    "    fused_model.spatial_layers[0], model.spatial_layers[0][1]\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(1, n_layers):\n",
    "    fused_model.spatial_layers[i] = fuse_conv_bn_eval(\n",
    "        model.spatial_layers[i][0], model.spatial_layers[i][1]\n",
    "    )\n",
    "\n",
    "for i in range(n_layers):\n",
    "    fused_model.feature_layers[i] = fuse_conv_bn_eval(\n",
    "        model.feature_layers[i][0], model.feature_layers[i][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model.decoder = model.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, 1, 1024).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(model(x), fused_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `torch.jit.trace` to turn the fused model into a `TorchScript`.\n",
    "\n",
    "Note that we convert the `dtype` of model and input to `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model.float()  # in-place operation\n",
    "x = x.float()\n",
    "with torch.no_grad():\n",
    "    traced_fused_model = torch.jit.trace(fused_model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_fused_model.save(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_model = torch.jit.load(save_file)\n",
    "torch.allclose(reload_model(x), fused_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the fused model without source code in our training of SNNs.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 1., 0., 1.],\n",
       "        [0., 1., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class StraightThroughEstimator(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return (x >= 0).to(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        return grad_out\n",
    "\n",
    "\n",
    "class SDNLIF(nn.Module):\n",
    "    model_path = save_file\n",
    "\n",
    "    def __init__(self, surrogate_func):\n",
    "        super().__init__()\n",
    "        self.model = torch.jit.load(self.model_path).eval()\n",
    "        self.surrogate_func = surrogate_func\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        m = self.pred(x)\n",
    "        s = self.surrogate_func(m + x - 1.0)\n",
    "        return s\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def pred(self, x):\n",
    "        shape = x.shape\n",
    "        L = x.size(-1)\n",
    "        return self.model(x.detach().view(-1, 1, L)).view(shape)\n",
    "\n",
    "\n",
    "test_model = SDNLIF(StraightThroughEstimator.apply)\n",
    "test_model(torch.randn(10, 1024))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
